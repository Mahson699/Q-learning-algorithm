%-------------------------------------------------------------------------------------
 % part 1 
% implementing Q-learning algorithm on the dynamical system in the Matlab


epsilon    = 0.9;
discount  = 0.99
alpha       = 0.01;
itration    = 2000;
episode   = 900;
S_0 = ?;     %should be described
action  =  [forward, up, down , back]; % for quad rotor

% there is states should be descrities ,
%for example you want to control pitch chaneel ,
%so it should be discrete also for another chaneels like
% yaw and roll

pitch = -0.5:0.01:+0.5;
Q = zeros( length(pitch) , length(action) ) ; 
Enviroment = zeros(itration,episodes);

%-----------------------------------------------------------------------------------------------
% part 2 

action_index     = randi(1,length(action));
state_index      = randi(1,length(action));
for j = 1: itration

S = S_0 ;  % for condition reseting in each itration
Enviroment(1,:) = S_0;
for i = 1:episode

% epsilon greedy action selection policy
if rand(0,1) < epsilon
action_index = randi(1,length(action));
act = action(1,action_index);
else
action_index = max(Q(state_index,action_index));
act  = action(1,action_index);
end

 [state,Reward] = quad(S,act);
 Enviroment(j,i) = state;

 state_index_new = find(round(state,2)==pitch);
 if numel(state_index_new)==0
 state_index_new = randi(1,length(state));
 end

 Q(state_index, action_index) = Q(state_index, action_index) + alpha*( R + discount*Q(state_index_new, action_index) - Q(state_index, action_index))
state_index = stete_index_new;

S = state;
end

%-----------------------------------------------------------------------------------------------
% part 3
% Results part
% display the you'r charts

end
